# -*- coding: utf-8 -*-
"""Protótico_LaserWeeder_Inteligencia_artificial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/BrunooPorto/LaserWeeder-Inteligencia-artificial/blob/main/Prot%C3%B3tico_LaserWeeder_Inteligencia_artificial.ipynb
"""

from google.colab import drive
drive.mount('/content/drive')

# Instalar bibliotecas necessárias
!pip install numpy pandas matplotlib tensorflow

# Criar diretórios para organizar os dados
import os
if not os.path.exists('DeepWeeds'):
    os.makedirs('DeepWeeds')

# Criar pasta para armazenar o kaggle.json
!mkdir -p ~/.kaggle
!cp /content/kaggle.json ~/.kaggle/

# Ajustar permissões do arquivo aqui está o meu token
!chmod 600 ~/.kaggle/kaggle.json

# Baixar o DeepWeeds Dataset do Kaggle usei o token/api
!kaggle datasets download -d imsparsh/deepweeds

# Criar diretório para o dataset e descompactar os arquivos
import os
import zipfile

if not os.path.exists('DeepWeeds'):
    os.makedirs('DeepWeeds')

with zipfile.ZipFile("/content/deepweeds.zip", 'r') as zip_ref:
    zip_ref.extractall("DeepWeeds")

print("Download e extração concluídos!")

import os
import matplotlib.pyplot as plt
from PIL import Image

# Diretório principal do dataset
dataset_dir = "DeepWeeds"

# Listar apenas os válidos
classes = [cls for cls in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, cls))]

# mostrar as classes disponíveis
print("Classes disponíveis:", classes)

# Contar imagens por classe
for cls in classes:
    cls_dir = os.path.join(dataset_dir, cls)
    num_images = len(os.listdir(cls_dir)) if os.path.isdir(cls_dir) else 0
    print(f"{cls}: {num_images} imagens")

# Exibir algumas imagens de cada classe
for cls in classes[:3]:  # Exibir apenas 3 classes como exemplo
    cls_dir = os.path.join(dataset_dir, cls)
    valid_files = [f for f in os.listdir(cls_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]

if valid_files:  # Garantir que há imagens válidas
        img_path = valid_files[0]
        img = Image.open(os.path.join(cls_dir, img_path))
        plt.imshow(img)
        plt.title(cls)
        plt.axis("off")
        plt.show()

import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical

def load_images_and_labels(dataset_dir, classes, img_size=(128, 128)):
    images = []
    labels = []
    # Iterar pelas classes e imagens
    for label, cls in enumerate(classes):
        cls_dir = os.path.join(dataset_dir, cls)
        valid_files = [f for f in os.listdir(cls_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]


        for img_file in valid_files:
            img_path = os.path.join(cls_dir, img_file)
            img = Image.open(img_path).resize(img_size)
            img = np.array(img)  # Converter para array numpy
            images.append(img)
            labels.append(label)  # A label é o índice da classe

    return images, labels

# Carregar imagens e labels
images, labels = load_images_and_labels(dataset_dir, classes)

import numpy as np

# dividir os dados em treino, validação e teste
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels)

# dividir o treino em treino e validação
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train)

# converter as listas de imagens para arrays NumPy
X_train = np.array(X_train)
X_val = np.array(X_val)
X_test = np.array(X_test)

# tratar as imagens (de [0, 255] para [0, 1])
X_train, X_val, X_test = X_train / 255.0, X_val / 255.0, X_test / 255.0

#converter para vetores
y_train = to_categorical(y_train, num_classes=len(classes))
y_val = to_categorical(y_val, num_classes=len(classes))
y_test = to_categorical(y_test, num_classes=len(classes))

# Criar geradores de imagem
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

# Geradores de treino e validação
train_generator = train_datagen.flow(X_train, y_train, batch_size=32)
val_generator = val_datagen.flow(X_val, y_val, batch_size=32)

print("Dados preparados e prontos para treinamento!")

import os
import random
import shutil

# Diretório principal do dataset
dataset_dir = "DeepWeeds"
base_dir = "DeepWeeds_split"

# Criar as pastas
if not os.path.exists(base_dir):
    os.makedirs(base_dir)
    for split in ["train", "val", "test"]:
        for cls in os.listdir(dataset_dir):
            cls_dir = os.path.join(base_dir, split, cls)
            os.makedirs(cls_dir, exist_ok=True)

# dividir os dados
def split_data(source_dir, dest_dir, split_ratios):
    classes = [cls for cls in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, cls))]
    for cls in classes:
        cls_dir = os.path.join(source_dir, cls)
        files = [f for f in os.listdir(cls_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]
        random.shuffle(files)

        train_size = int(split_ratios[0] * len(files))
        val_size = int(split_ratios[1] * len(files))

        train_files = files[:train_size]
        val_files = files[train_size:train_size + val_size]
        test_files = files[train_size + val_size:]

        for file in train_files:
            shutil.copy(os.path.join(cls_dir, file), os.path.join(dest_dir, "train", cls))
        for file in val_files:
            shutil.copy(os.path.join(cls_dir, file), os.path.join(dest_dir, "val", cls))
        for file in test_files:
            shutil.copy(os.path.join(cls_dir, file), os.path.join(dest_dir, "test", cls))

# Dividir os dados: 70% treino, 15% validação, 15% teste (coloquei nesses valores.. testar outros dps)
split_data(dataset_dir, base_dir, split_ratios=(0.7, 0.15, 0.15))

print("Divisão dos dados concluída!")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# colocar o diretório base
base_dir = "DeepWeeds_split"

# config dos geradores de dados
#colocar parametros aleatorios para configurar leitura
train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_test_datagen = ImageDataGenerator(rescale=1.0/255)  # configurar escala para normalizar

# generatorss para treino, validação e teste
train_generator = train_datagen.flow_from_directory(
    os.path.join(base_dir, "train"),
    target_size=(224, 224),  # Redimensionar imagens
    batch_size=32,
    class_mode='categorical'  # classes
)

val_generator = val_test_datagen.flow_from_directory(
    os.path.join(base_dir, "val"),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

test_generator = val_test_datagen.flow_from_directory(
    os.path.join(base_dir, "test"),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False  # para não embaralhar
)

print("Geradores configurados com sucesso!")

# Test do gerador de treino
import matplotlib.pyplot as plt

# catar as imagens e rótulos
images, labels = next(train_generator)

# mostrar exemplos de imagens
plt.figure(figsize=(10, 10))
for i in range(9):  # numero de imgens
    plt.subplot(3, 3, i + 1)
    plt.imshow(images[i])
    plt.title(f"Classe: {train_generator.class_indices}")
    plt.axis('off')
plt.show()

#pegar o que precisamos
#https://keras.io/api/applications/mobilenet/
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.optimizers import Adam

#esse demorou demais.. n sei pq

# Tentar carregar o MobileNetV2 (o v3 é em blocos, talvez n funcione)
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

base_model.trainable = False

# Construir o modelo
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),  # Reduz a saída da base para um vetor de características
    layers.Dense(128, activation='relu'),  # Camada densa com 128 neurônios (geralmente dizem ser um bom numero)
    layers.Dropout(0.5),
    layers.Dense(len(train_generator.class_indices), activation='softmax')
])

# Compilar o modelo
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Resumo do modelo
model.summary()

# vamo treinar o modelo
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=6,  # Ajustar de acordo com o seu pc, senão pc explode kkk brincadeira
    steps_per_epoch=len(train_generator),
    validation_steps=len(val_generator)
)
#paciência aqui é onde mais demora, é o treino da sua IA
# Salvar o modelo
model.save("deepweeds_model.h5")

import matplotlib.pyplot as plt

# para visualizar o desempenho
plt.figure(figsize=(12, 5))

# acurácia/precisão
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Treino')
plt.plot(history.history['val_accuracy'], label='Validação')
plt.title('Acurácia')
plt.legend()

# perda/ erros
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Treino')
plt.plot(history.history['val_loss'], label='Validação')
plt.title('Perda')
plt.legend()

plt.show()

# avaliar conjunto de teste
test_loss, test_accuracy = model.evaluate(test_generator)

print(f"Perda no teste: {test_loss}")
print(f"Acurácia no teste: {test_accuracy}")

import numpy as np

# Fazer previsões no conjunto de teste
predictions = model.predict(test_generator, steps=len(test_generator), verbose=1)

# Obter as classes previstas e reais
predicted_classes = np.argmax(predictions, axis=1)
true_classes = test_generator.classes

# Mostrar as primeiras 10 previsões
for i in range(10):
    print(f"Imagem {i + 1}")
    print(f"Classe verdadeira: {test_generator.class_indices}")
    print(f"Classe prevista: {predicted_classes[i]}")
    print()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Obter a matriz de confusão
cm = confusion_matrix(true_classes, predicted_classes)

# Plotar a matriz de confusão
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())
plt.xlabel('Classe Predita')
plt.ylabel('Classe Verdadeira')
plt.title('Matriz de Confusão')
plt.show()

# Visualizando as previsões
plt.figure(figsize=(12, 10))
for i in range(9):  # Mostrar x imagens
    plt.subplot(3, 3, i + 1)

    # Obter uma imagem  do gerador
    img, label = test_generator[i]

    # Prever a classe da imagem
    pred = np.argmax(model.predict(img), axis=1)[0]  # Prever a classe para a imagem

    # Verificar se o label é one-hot encoded ou um índice
    if len(label.shape) > 1:  # esse é o erro que fica dando, corrigir ele e jogar para label 0
        label = np.argmax(label, axis=1)[0]

    # Mostrando a imagem
    plt.imshow(img[0])  # img[0] já é a imagem na forma correta

    # Obter o nome das classes
    predicted_class = list(test_generator.class_indices.keys())[pred]
    real_class = list(test_generator.class_indices.keys())[label]  # Usando o real class

    # Exibir o título
    plt.title(f"Predição: {predicted_class}\nReal: {real_class}")
    plt.axis('off')

plt.show()

import ipywidgets as widgets
from IPython.display import display
from PIL import Image
import numpy as np

# Função para carregar uma imagem
def predict_image(uploaded_file):
    img = Image.open(uploaded_file['file'])
    img = img.resize((224, 224))  # Ajustar o tamanho para evitar erro no modelo
    img_array = np.array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    # Fazer a predição
    pred = np.argmax(model.predict(img_array), axis=1)[0]

    # Mostrar a imagem
    plt.imshow(img)
    plt.title(f"Predição: {list(test_generator.class_indices.keys())[pred]}")
    plt.axis('off')
    plt.show()

# Widget de upload de imagem
upload_widget = widgets.FileUpload(accept='.jpg,.png', multiple=False)
upload_widget.observe(lambda change: predict_image(change['new'][0]), names='value')

display(upload_widget)
#assim a pessoa pode subir uma imagem de planta e verificar o uso na hora, se é ou não uma weeder

#novamente uma matriz d confusão
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Previsões de teste
y_true = test_generator.classes
y_pred = model.predict(test_generator, verbose=1)
y_pred_classes = np.argmax(y_pred, axis=1)

# Gerar a matriz de confusão
conf_matrix = confusion_matrix(y_true, y_pred_classes)

# fazer o plot da matriz de confusão
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())
plt.title('Matriz de Confusão')
plt.xlabel('Classe Predita')
plt.ylabel('Classe Real')
plt.show()

#mais gráficos para melhorar visualização

# Gráfico de precisão
plt.plot(history.history['accuracy'], label='Precisão (Treinamento)')
plt.plot(history.history['val_accuracy'], label='Precisão (Validação)')
plt.title('Precisão do Modelo')
plt.xlabel('Épocas')
plt.ylabel('Precisão')
plt.legend()
plt.show()

# Gráfico de perda
plt.plot(history.history['loss'], label='Perda (Treinamento)')
plt.plot(history.history['val_loss'], label='Perda (Validação)')
plt.title('Perda do Modelo')
plt.xlabel('Épocas')
plt.ylabel('Perda')
plt.legend()
plt.show()

#salvar tudo agora e baixar para fazer os dashboards
# essa célula não é necessária caso não queira, é só para criar
# dashboards interativos no streamlit ou Power Bi
model.save("deepweeds_model.h5")
from google.colab import files
files.download("deepweeds_model.h5")  # Baixar o modelo para o computador

print(f"Tamanho de y_test: {len(y_test)}")
print(f"Tamanho de y_pred: {len(y_pred)}")

#Isso garantirá que y_test e y_pred tenham o mesmo tamanho.

y_test = y_test[:len(y_pred)]
print(f"Tamanho ajustado de y_test: {len(y_test)}")
print(f"Tamanho de y_pred: {len(y_pred)}")

#Vamos também confirmar os tamanhos novamente:

# Agora eles tem o mesmo tamanho
# vamos gerar predições completas
y_pred = model.predict(test_generator)
y_pred = np.argmax(y_pred, axis=1)  # Transformar probabilidades em classes

# revalidar que y_test é gerado corretamente
# Obter rótulos reais
y_test = test_generator.classes

print("Classes únicas em y_pred:", np.unique(y_pred))
print("Classes únicas em y_test:", np.unique(y_test))
print("Nomes das classes em test_generator:", list(test_generator.class_indices.keys()))

#verificar se pegou as classes

# Certicando de usar o gerador completo
predictions = model.predict(test_generator, verbose=1)

# Converter as probabilidades para classes
y_pred = np.argmax(predictions, axis=1)

print("Tamanho de y_pred:", len(y_pred))
print("Tamanho de y_test:", len(y_test))

#ajustando tamanhos

#necessário importar umas bibliotecas para n ter erro
!pip install scikit-learn
import pandas as pd #import pandas para dataframe
import matplotlib.pyplot as plt #import pyplot para plotting
import seaborn as sns #import seaborn para heatmap
from sklearn.metrics import classification_report, confusion_matrix

#começar a criar os dashboards dentro do colab


# Obter métricas detalhadas
report = classification_report(
    y_test,
    y_pred,
    labels=labels,
    target_names=list(test_generator.class_indices.keys()),
    output_dict=True
)

# Converter para DataFrame
metrics_df = pd.DataFrame(report).transpose()

# Plotar as métricas por classe
fig, ax = plt.subplots(figsize=(10, 6))
metrics_df[:-3][['precision', 'recall', 'f1-score']].plot(kind='bar', ax=ax, rot=45)
plt.title("Métricas de Precisão, Recall e F1-Score por Classe", fontsize=16)
plt.ylabel("Valores", fontsize=12)
plt.xlabel("Classes", fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.xticks(fontsize=10)
plt.legend(fontsize=10)
plt.tight_layout()
plt.show()

# Esse gráfico será um gráfico de barras comparando as métricas principais
# por classe, destacando os pontos fortes e fracos do modelo.

# Matriz de Confusão
cm = confusion_matrix(y_test, y_pred)
fig, ax = plt.subplots(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys(), ax=ax)

plt.title("Matriz de Confusão", fontsize=16)
plt.ylabel("Classes Reais", fontsize=12)
plt.xlabel("Classes Previstas", fontsize=12)
plt.tight_layout()
plt.show()

#outra matriz de confusão, não deve ter alteração.. já que está dando 100% de acerto

# Salvar gráficos
fig.savefig("metrics_by_class.png")  # Salva o gráfico de métricas
fig.savefig("confusion_matrix.png")  # Salva a matriz de confusão

def predict_uploaded_image(change):
    clear_output(wait=True)  # Limpar saídas anteriores
    uploaded_file = next(iter(change['new'].values()))  # Extrair o arquivo
    if uploaded_file:
        # Obter o conteúdo do arquivo como BytesIO
        file_content = io.BytesIO(uploaded_file['content'])

        # Carregar a imagem
        img = Image.open(file_content)  # Abrir diretamente o conteúdo
        img = img.resize((224, 224))  # Redimensionar para o modelo
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        # Fazer a predição
        predictions = model.predict(img_array)  # Obter todas as probabilidades
        pred_class = np.argmax(predictions, axis=1)[0]  # Classe com maior probabilidade
        class_name = list(test_generator.class_indices.keys())[pred_class]  # Nome da classe

        # Debugging: Mostrar probabilidades
        print("Predições (Probabilidades por Classe):", predictions)
        print("Classe Predita:", class_name)

        # Verificar se é erva daninha
        weed_classes = ["nome_da_classe_weeds"]  # Substitua pelo nome da(s) classe(s) de erva daninha
        is_weed = "É erva daninha" if class_name in weed_classes else "Não é erva daninha"

        # Mostrar a imagem com o resultado
        plt.imshow(img)
        plt.title(f"Predição: {is_weed} ({class_name})")
        plt.axis('off')
        plt.show()

import ipywidgets as widgets
from IPython.display import display, clear_output
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import io

# Função para carregar e processar a imagem
def predict_uploaded_image(change):
    clear_output(wait=True)  # Limpar saídas anteriores
    uploaded_file = next(iter(change['new'].values()))  # Extrair o arquivo
    if uploaded_file:
        # Obter o conteúdo do arquivo como BytesIO
        file_content = io.BytesIO(uploaded_file['content'])

        # Carregar a imagem
        img = Image.open(file_content)  # Abrir diretamente o conteúdo
        img = img.resize((224, 224))  # Redimensionar para o modelo
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        # Fazer a predição
        pred = np.argmax(model.predict(img_array), axis=1)[0]
        class_name = list(test_generator.class_indices.keys())[pred]
        is_weed = "É erva daninha" if class_name.lower() in ["nome_da_classe_weeds"] else "Não é erva daninha"

        # Mostrar a imagem com o resultado
        plt.imshow(img)
        plt.title(f"Predição: {is_weed}")
        plt.axis('off')
        plt.show()

# Widget para upload de imagens
upload_widget = widgets.FileUpload(accept='.jpg,.png', multiple=False)
upload_widget.observe(predict_uploaded_image, names='value')

# Mostrar o widget
display(widgets.HTML("<h3>Faça upload de uma imagem para verificar:</h3>"))
display(upload_widget)